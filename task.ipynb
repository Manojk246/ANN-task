{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d69bfb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.128232</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.444686</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.174752</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.280934</td>\n",
       "      <td>0.093490</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.518794</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.174752</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>0.088011</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.501436</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.072321</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.457425</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.128232</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.444686</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       2.128232          0.530628         0.00        1.064711   0.073250   \n",
       "1       2.174752          0.631272         0.00        1.280934   0.093490   \n",
       "2       2.174752          0.565314         0.04        1.193922   0.088011   \n",
       "3       2.501436          0.246860         0.56        1.064711   0.072321   \n",
       "4       2.128232          0.530628         0.00        1.064711   0.073250   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0             2.484907              3.555348   0.9978  3.51   0.444686   \n",
       "1             3.258097              4.219508   0.9968  3.20   0.518794   \n",
       "2             2.772589              4.007333   0.9970  3.26   0.500775   \n",
       "3             2.890372              4.110874   0.9980  3.16   0.457425   \n",
       "4             2.484907              3.555348   0.9978  3.51   0.444686   \n",
       "\n",
       "    alcohol  quality  \n",
       "0  2.341806        5  \n",
       "1  2.379546        5  \n",
       "2  2.379546        5  \n",
       "3  2.379546        6  \n",
       "4  2.341806        5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "df = pd.read_csv('modified.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d82c4ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c03962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()\n",
    "def map_quality(val):\n",
    "    if val in [3,4]:\n",
    "        return 0\n",
    "    elif val in [5,6]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['quality_class'] = df['quality'].apply(map_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62c61383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.128232</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.444686</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.174752</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.280934</td>\n",
       "      <td>0.093490</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.518794</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.174752</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>0.088011</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.501436</td>\n",
       "      <td>0.246860</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.072321</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.457425</td>\n",
       "      <td>2.379546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.128232</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.444686</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1.974081</td>\n",
       "      <td>0.470004</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.086178</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.457425</td>\n",
       "      <td>2.442347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1.931521</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.163151</td>\n",
       "      <td>0.060154</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>2.501436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1.987874</td>\n",
       "      <td>0.412110</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1.931521</td>\n",
       "      <td>0.497740</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.072321</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.536493</td>\n",
       "      <td>2.415914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.270027</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>0.064851</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.506818</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          2.128232          0.530628         0.00        1.064711   0.073250   \n",
       "1          2.174752          0.631272         0.00        1.280934   0.093490   \n",
       "2          2.174752          0.565314         0.04        1.193922   0.088011   \n",
       "3          2.501436          0.246860         0.56        1.064711   0.072321   \n",
       "4          2.128232          0.530628         0.00        1.064711   0.073250   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594       1.974081          0.470004         0.08        1.098612   0.086178   \n",
       "1595       1.931521          0.438255         0.10        1.163151   0.060154   \n",
       "1596       1.987874          0.412110         0.13        1.193922   0.073250   \n",
       "1597       1.931521          0.497740         0.12        1.098612   0.072321   \n",
       "1598       1.945910          0.270027         0.47        1.526056   0.064851   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                2.484907              3.555348  0.99780  3.51   0.444686   \n",
       "1                3.258097              4.219508  0.99680  3.20   0.518794   \n",
       "2                2.772589              4.007333  0.99700  3.26   0.500775   \n",
       "3                2.890372              4.110874  0.99800  3.16   0.457425   \n",
       "4                2.484907              3.555348  0.99780  3.51   0.444686   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594             3.496508              3.806662  0.99490  3.45   0.457425   \n",
       "1595             3.688879              3.951244  0.99512  3.52   0.565314   \n",
       "1596             3.401197              3.713572  0.99574  3.42   0.559616   \n",
       "1597             3.496508              3.806662  0.99547  3.57   0.536493   \n",
       "1598             2.944439              3.761200  0.99549  3.39   0.506818   \n",
       "\n",
       "       alcohol  quality_class  \n",
       "0     2.341806              1  \n",
       "1     2.379546              1  \n",
       "2     2.379546              1  \n",
       "3     2.379546              1  \n",
       "4     2.341806              1  \n",
       "...        ...            ...  \n",
       "1594  2.442347              1  \n",
       "1595  2.501436              1  \n",
       "1596  2.484907              1  \n",
       "1597  2.415914              1  \n",
       "1598  2.484907              1  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed38fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['quality'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88516040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quality_class', axis=1)\n",
    "y = df['quality_class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "num_classes = len(encoder.classes_)  # number of unique classes\n",
    "y_train_cat = to_categorical(y_train_enc, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test_enc, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a485c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj\\anaconda4\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7908 - loss: 0.6827 - val_accuracy: 0.7891 - val_loss: 0.6069\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.5029 - val_accuracy: 0.8125 - val_loss: 0.5329\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.4740 - val_accuracy: 0.8086 - val_loss: 0.5153\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.4492 - val_accuracy: 0.8125 - val_loss: 0.5057\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.4502 - val_accuracy: 0.8125 - val_loss: 0.4949\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.4296 - val_accuracy: 0.8164 - val_loss: 0.4934\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.4187 - val_accuracy: 0.8164 - val_loss: 0.4809\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4140 - val_accuracy: 0.8242 - val_loss: 0.4830\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.4222 - val_accuracy: 0.8438 - val_loss: 0.4822\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.3975 - val_accuracy: 0.8164 - val_loss: 0.4856\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 0.4010 - val_accuracy: 0.8281 - val_loss: 0.4787\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8368 - loss: 0.4053 - val_accuracy: 0.8477 - val_loss: 0.4688\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.3978 - val_accuracy: 0.8320 - val_loss: 0.4752\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8475 - loss: 0.3926 - val_accuracy: 0.8320 - val_loss: 0.4679\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8524 - loss: 0.3917 - val_accuracy: 0.8281 - val_loss: 0.4758\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8426 - loss: 0.3840 - val_accuracy: 0.8242 - val_loss: 0.4700\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8475 - loss: 0.3850 - val_accuracy: 0.8281 - val_loss: 0.4737\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.3842 - val_accuracy: 0.8281 - val_loss: 0.4662\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8534 - loss: 0.3610 - val_accuracy: 0.8320 - val_loss: 0.4688\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8563 - loss: 0.3799 - val_accuracy: 0.8320 - val_loss: 0.4715\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8602 - loss: 0.3622 - val_accuracy: 0.8281 - val_loss: 0.4617\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.3758 - val_accuracy: 0.8320 - val_loss: 0.4643\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8563 - loss: 0.3628 - val_accuracy: 0.8242 - val_loss: 0.4700\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8651 - loss: 0.3583 - val_accuracy: 0.8320 - val_loss: 0.4545\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8534 - loss: 0.3474 - val_accuracy: 0.8320 - val_loss: 0.4588\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3567 - val_accuracy: 0.8203 - val_loss: 0.4675\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8475 - loss: 0.3623 - val_accuracy: 0.8359 - val_loss: 0.4603\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8456 - loss: 0.3564 - val_accuracy: 0.8359 - val_loss: 0.4576\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8602 - loss: 0.3470 - val_accuracy: 0.8281 - val_loss: 0.4569\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.3425 - val_accuracy: 0.8242 - val_loss: 0.4688\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.3393 - val_accuracy: 0.8320 - val_loss: 0.4618\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.3505 - val_accuracy: 0.8320 - val_loss: 0.4549\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.3376 - val_accuracy: 0.8359 - val_loss: 0.4571\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8651 - loss: 0.3314 - val_accuracy: 0.8398 - val_loss: 0.4643\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8602 - loss: 0.3394 - val_accuracy: 0.8242 - val_loss: 0.4563\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.3374 - val_accuracy: 0.8359 - val_loss: 0.4592\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.3346 - val_accuracy: 0.8320 - val_loss: 0.4536\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.3388 - val_accuracy: 0.8359 - val_loss: 0.4579\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.3386 - val_accuracy: 0.8398 - val_loss: 0.4560\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8641 - loss: 0.3283 - val_accuracy: 0.8320 - val_loss: 0.4647\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8612 - loss: 0.3233 - val_accuracy: 0.8359 - val_loss: 0.4581\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.3272 - val_accuracy: 0.8281 - val_loss: 0.4659\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8592 - loss: 0.3363 - val_accuracy: 0.8281 - val_loss: 0.4668\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8700 - loss: 0.3183 - val_accuracy: 0.8359 - val_loss: 0.4557\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8759 - loss: 0.3329 - val_accuracy: 0.8320 - val_loss: 0.4609\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.3079 - val_accuracy: 0.8281 - val_loss: 0.4709\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.3135 - val_accuracy: 0.8359 - val_loss: 0.4656\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8641 - loss: 0.3114 - val_accuracy: 0.8359 - val_loss: 0.4634\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8719 - loss: 0.3020 - val_accuracy: 0.8359 - val_loss: 0.4683\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8700 - loss: 0.3187 - val_accuracy: 0.8359 - val_loss: 0.4634\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - loss: 0.3063 - val_accuracy: 0.8398 - val_loss: 0.4827\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8729 - loss: 0.2964 - val_accuracy: 0.8320 - val_loss: 0.4704\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8729 - loss: 0.3062 - val_accuracy: 0.8398 - val_loss: 0.4604\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8631 - loss: 0.3118 - val_accuracy: 0.8438 - val_loss: 0.4750\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8778 - loss: 0.3009 - val_accuracy: 0.8398 - val_loss: 0.4725\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8680 - loss: 0.3030 - val_accuracy: 0.8398 - val_loss: 0.4645\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8837 - loss: 0.2917 - val_accuracy: 0.8398 - val_loss: 0.4679\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8788 - loss: 0.2935 - val_accuracy: 0.8398 - val_loss: 0.4655\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8778 - loss: 0.2901 - val_accuracy: 0.8398 - val_loss: 0.4807\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.2894 - val_accuracy: 0.8398 - val_loss: 0.4815\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.2822 - val_accuracy: 0.8398 - val_loss: 0.4797\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8768 - loss: 0.2920 - val_accuracy: 0.8438 - val_loss: 0.4776\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8876 - loss: 0.2800 - val_accuracy: 0.8477 - val_loss: 0.4851\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2786 - val_accuracy: 0.8359 - val_loss: 0.4742\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.2733 - val_accuracy: 0.8477 - val_loss: 0.4849\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.2779 - val_accuracy: 0.8359 - val_loss: 0.4738\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.2745 - val_accuracy: 0.8477 - val_loss: 0.4755\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.2815 - val_accuracy: 0.8438 - val_loss: 0.4892\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.2768 - val_accuracy: 0.8438 - val_loss: 0.4724\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2871 - val_accuracy: 0.8398 - val_loss: 0.4834\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2637 - val_accuracy: 0.8438 - val_loss: 0.5018\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.2776 - val_accuracy: 0.8398 - val_loss: 0.4918\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.2674 - val_accuracy: 0.8398 - val_loss: 0.4909\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8954 - loss: 0.2706 - val_accuracy: 0.8438 - val_loss: 0.4939\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2581 - val_accuracy: 0.8398 - val_loss: 0.5051\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8935 - loss: 0.2772 - val_accuracy: 0.8398 - val_loss: 0.4926\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2765 - val_accuracy: 0.8398 - val_loss: 0.4962\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8817 - loss: 0.2669 - val_accuracy: 0.8438 - val_loss: 0.4954\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8827 - loss: 0.2750 - val_accuracy: 0.8438 - val_loss: 0.4961\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9003 - loss: 0.2597 - val_accuracy: 0.8398 - val_loss: 0.5009\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.2855 - val_accuracy: 0.8359 - val_loss: 0.4903\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8954 - loss: 0.2614 - val_accuracy: 0.8477 - val_loss: 0.5008\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8944 - loss: 0.2716 - val_accuracy: 0.8477 - val_loss: 0.5051\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.2530 - val_accuracy: 0.8359 - val_loss: 0.4876\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2653 - val_accuracy: 0.8438 - val_loss: 0.4863\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.2456 - val_accuracy: 0.8398 - val_loss: 0.4983\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.2517 - val_accuracy: 0.8438 - val_loss: 0.5088\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8964 - loss: 0.2694 - val_accuracy: 0.8438 - val_loss: 0.4909\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2488 - val_accuracy: 0.8398 - val_loss: 0.5117\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.2630 - val_accuracy: 0.8359 - val_loss: 0.4977\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8935 - loss: 0.2547 - val_accuracy: 0.8438 - val_loss: 0.5148\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.2641 - val_accuracy: 0.8516 - val_loss: 0.5039\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2375 - val_accuracy: 0.8438 - val_loss: 0.5144\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8944 - loss: 0.2529 - val_accuracy: 0.8438 - val_loss: 0.5151\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2514 - val_accuracy: 0.8477 - val_loss: 0.5238\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8895 - loss: 0.2516 - val_accuracy: 0.8398 - val_loss: 0.5109\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2429 - val_accuracy: 0.8359 - val_loss: 0.5221\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2484 - val_accuracy: 0.8359 - val_loss: 0.5236\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.2376 - val_accuracy: 0.8359 - val_loss: 0.5176\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2352 - val_accuracy: 0.8398 - val_loss: 0.5201\n",
      "✅ Test Accuracy: 0.859375\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax')) \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(\"✅ Test Accuracy:\", test_acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
